{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVGGModel():\n",
    "  vgg16 = models.vgg16_bn(weights=models.vgg.VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "\n",
    "  # Fix the conv layers parameters\n",
    "  for conv_param in vgg16.features.parameters():\n",
    "    conv_param.require_grad = False\n",
    "\n",
    "  # Replace w/ new classification layers\n",
    "  classifications = nn.Sequential(\n",
    "    nn.Linear(25088,2048),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(2048,3)\n",
    "  )\n",
    "\n",
    "  vgg16.classifier = classifications\n",
    "\n",
    "  return vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = getVGGModel()\n",
    "    \n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\"lr\":1e-5, \"beta1\":0.9, \"beta2\":0.999, \"batch_size\":16, \"epochs\":5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load dataset and define data augmentation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(train_path, val_path, test_path):\n",
    "  val_img_transform = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "  train_img_transform = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                            transforms.RandomAffine(degrees=0, scale=(0.8,1.2), shear=0.2, translate=(0.2, 0.2)), \n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Resize((244,244)), \n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "  train_dataset = datasets.ImageFolder(train_path, transform=train_img_transform)\n",
    "  val_dataset = datasets.ImageFolder(val_path, transform=val_img_transform) \n",
    "  test_dataset = datasets.ImageFolder(test_path, transform=val_img_transform) if test_path is not None else None\n",
    "  print(f\"Train set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
    "  return train_dataset, val_dataset, test_dataset\n",
    "    \n",
    "def construct_dataloaders(train_set, val_set, test_set, batch_size, shuffle=True):\n",
    "  train_dataloader = torch.utils.data.DataLoader(train_set, batch_size, shuffle)\n",
    "  val_dataloader = torch.utils.data.DataLoader(val_set, batch_size) \n",
    "  test_dataloader = torch.utils.data.DataLoader(test_aset, batch_size) if test_path is not None else None\n",
    "  return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1322, Validation set size: 363\n"
     ]
    }
   ],
   "source": [
    "# Please specify the path to train, cross_validation, and test images below:\n",
    "train_path, val_path, test_path = \"/tmp/Dataset_2/Train/\", \"/tmp/Dataset_2/Validation/\", None\n",
    "train_set, val_set, test_set = load_datasets(train_path, val_path, test_path)\n",
    "train_dataloader, val_dataloader, test_dataloader = construct_dataloaders(train_set, val_set, test_set, hp[\"batch_size\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"], betas=(hp[\"beta1\"], hp[\"beta2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(data_loader, model, loss_fn, DEVICE):\n",
    "  model.train(False)\n",
    "  model.eval()\n",
    "  loss, accuracy = 0.0, 0.0\n",
    "  n = len(data_loader)\n",
    "\n",
    "  for i, data in enumerate(data_loader):\n",
    "    x,y = data\n",
    "    x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "    pred = model(x)\n",
    "    loss += loss_fn(pred, y)/len(x)\n",
    "    pred_label = torch.argmax(pred, axis = 1)\n",
    "    accuracy += torch.sum(pred_label == y)/len(x)\n",
    "\n",
    "  return loss/n, accuracy/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Define evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, opt, loss_fn, epochs, DEVICE):\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    model.train(True)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    with tqdm(\n",
    "        total=len(train_loader),\n",
    "        bar_format='{l_bar}{bar:10}{r_bar}',\n",
    "        desc=f'Epoch {epoch:3d}/{epochs:3d}',\n",
    "        disable=False\n",
    "    ) as t:\n",
    "        for x, y in train_loader:\n",
    "          x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "          pred = model(x)\n",
    "          loss = loss_fn(pred,y)\n",
    "\n",
    "          opt.zero_grad()\n",
    "          loss.backward()\n",
    "          opt.step()\n",
    "\n",
    "          pred_label = torch.argmax(pred, axis=1)\n",
    "          total_loss += loss\n",
    "          total_accuracy += torch.sum(pred_label == y)\n",
    "          total_count += len(x)\n",
    "          t.set_postfix_str(\n",
    "                    'loss: {:.4f}, acc: {:.2f}%'.format(\n",
    "                        total_loss/total_count,\n",
    "                        100*total_accuracy/total_count,\n",
    "                    ),\n",
    "                )\n",
    "          t.update(1)\n",
    "      \n",
    "      \n",
    "    end_time = datetime.now()    \n",
    "    print(f\"Time: {(end_time-start_time).seconds}s\")\n",
    "\n",
    "    val_loss, val_acc = eval_model(val_loader, model, loss_fn, DEVICE)\n",
    "    print(f\"Val loss: {val_loss}, Val accuracy: {val_acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   0/  5: 100%|██████████| 83/83 [07:44<00:00,  5.60s/it, loss: 0.0611, acc: 53.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 464s\n",
      "Val loss: 0.05047643184661865, Val accuracy: 0.6916996240615845\n",
      "\n",
      "Epoch 2/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/  5: 100%|██████████| 83/83 [08:05<00:00,  5.85s/it, loss: 0.0467, acc: 67.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 485s\n",
      "Val loss: 0.04201819747686386, Val accuracy: 0.7028161883354187\n",
      "\n",
      "Epoch 3/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   2/  5: 100%|██████████| 83/83 [07:40<00:00,  5.55s/it, loss: 0.0396, acc: 73.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 460s\n",
      "Val loss: 0.04148910567164421, Val accuracy: 0.6810771226882935\n",
      "\n",
      "Epoch 4/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   3/  5: 100%|██████████| 83/83 [08:20<00:00,  6.03s/it, loss: 0.0359, acc: 74.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 500s\n",
      "Val loss: 0.039522796869277954, Val accuracy: 0.7000988125801086\n",
      "\n",
      "Epoch 5/5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   4/  5: 100%|██████████| 83/83 [07:41<00:00,  5.57s/it, loss: 0.0301, acc: 78.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 462s\n",
      "Val loss: 0.03911827132105827, Val accuracy: 0.7245553135871887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, val_dataloader, model, opt, loss_fn, hp[\"epochs\"], DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
